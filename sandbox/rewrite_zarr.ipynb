{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/cmocean/tools.py:76: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.\n",
      "  if not mpl.cbook.is_string_like(rgbin[0]):\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/distributed/utils.py:128: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable\n",
      "  % (host, default, e), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster()\n",
    "w = cluster.start_workers(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.1.2:43866\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.1.2:8787/status' target='_blank'>http://10.148.1.2:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.1.2:43866' processes=0 cores=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zarr compression\n",
    "# http://xarray.pydata.org/en/stable/io.html\n",
    "# http://zarr.readthedocs.io/en/stable/tutorial.html#compressors\n",
    "compressor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# store grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:735: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:249: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, i_g: 4320, j: 4320, j_g: 4320, k: 90, k_l: 90, k_p1: 91, k_u: 90)\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "    XC       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "    YC       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "    XG       (face, j_g, i_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "    YG       (face, j_g, i_g) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "    rA       (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "    Depth    (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(1, 96, 96)>\n",
      "Data variables:\n",
      "    *empty*\n",
      "Attributes:\n",
      "    Conventions:  CF-1.6\n",
      "    title:        netCDF wrapper of MITgcm MDS binary data\n",
      "    source:       MITgcm\n",
      "    history:      Created by calling `open_mdsdataset(llc_method='smallchunks...\n"
     ]
    }
   ],
   "source": [
    "ds_index, ds = get_compressed_level_index(grid_dir)\n",
    "\n",
    "# we will need to keep some of these when computing gradients\n",
    "ds = ds.drop(['dxG','dyG','dxC','dyC','rAw','rAs','rAz'])\n",
    "ds = ds.drop(['hFacC','hFacW','hFacS'])\n",
    "ds = ds.drop(['Z', 'Zp1', 'Zu', 'Zl', 'drC', 'drF','PHrefC','PHrefF'])\n",
    "\n",
    "#Nc = 432 # original choice\n",
    "#Nc = 27 # very long scheduling\n",
    "Nc = 96 # 96*45\n",
    "ds = ds.chunk({'i': Nc, 'j': Nc, 'i_g': Nc, 'j_g': Nc})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = scratch+'mit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 4.76 s, total: 3min 39s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x2aab174e5b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out = out_dir+'grid.zarr'\n",
    "%time ds.to_zarr(file_out, mode='w')\n",
    "#%time ds.to_zarr(file_out, mode='w', encoding={key: {'compressor': compressor} for key in ds.variables})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 3.95 s, total: 3min 25s\n",
      "Wall time: 3min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x2aab3b56bdd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out = out_dir+'grid_nocompression.zarr'\n",
    "%time ds.to_zarr(file_out, mode='w', encoding={key: {'compressor': compressor} for key in ds.variables})\n",
    "# about 30s faster\n",
    "# 5.5G vs 1.6G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# standard data layout: chunks (face, time, j, i) = (1, 1, 4320, 4320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:735: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:249: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, j: 4320, time: 8785)\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 5.713e+06 5.717e+06 ...\n",
      "    dtime    (time) datetime64[ns] dask.array<shape=(8785,), chunksize=(8785,)>\n",
      "Data variables:\n",
      "    SSU      (time, face, j, i) >f4 dask.array<shape=(8785, 13, 4320, 4320), chunksize=(1, 1, 4320, 4320)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 39s, sys: 22.6 s, total: 9min 2s\n",
      "Wall time: 17min 37s\n",
      "   data is 4082.8GB \n"
     ]
    }
   ],
   "source": [
    "#V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "#V = ['SSU', 'SSV']\n",
    "V = ['SSU']\n",
    "\n",
    "# scheduler does not like (i.e. takes a long time to do anything) any spatial rechunking on top \n",
    "# of that on faces:\n",
    "#Nc = 480 # x 9 = 4320\n",
    "#Nc = 96 # x 45 = 4320\n",
    "# other choices: 432, 27 (long scheduling), 288, 864\n",
    "\n",
    "out_dir = scratch+'/mit/standard/'\n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    p = 'C'\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    #\n",
    "    # should store grid data independantly in a single file\n",
    "    ds = ds.drop(['XC','YC','Depth','rA'])\n",
    "    #\n",
    "    ds = ds.chunk({'face': 1})\n",
    "    #ds = ds.chunk({'face': 1, 'i': Nc, 'j': Nc}) # scheduler does not like this\n",
    "    #\n",
    "    dv = ds[v].to_dataset()\n",
    "    #\n",
    "    #dv = dv.chunk({'i': Nc, 'j': Nc}) # scheduler does not like this either\n",
    "    #\n",
    "    file_out = out_dir+'/%s.zarr'%(v)\n",
    "    try:\n",
    "        print(dv)\n",
    "        %time dv.to_zarr(file_out, mode='w')                    \n",
    "    except:\n",
    "        print('Failure')\n",
    "    dsize = getsize(file_out)\n",
    "    print('   data is %.1fGB ' %(dsize/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# try to load standard lay out, rechunk and store right away\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for rechunking\n",
    "\n",
    "Nt = 24*10 # time chunks\n",
    "#Nt = 0\n",
    "#\n",
    "Nt = len(ds.time) if Nt == 0 else Nt\n",
    "\n",
    "Nc = 96 # x 45 = 4320\n",
    "# other choices: 432, 27 (long scheduling), 288, 864"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one face at a time, all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 24s, sys: 23.9 s, total: 8min 48s\n",
      "Wall time: 14min 49s\n",
      " SSU face=1  data is 628.6GB \n"
     ]
    }
   ],
   "source": [
    "# same but over all variables and faces\n",
    "#V = ['SSU', 'SSV']\n",
    "V = ['SSU']\n",
    "\n",
    "out_dir = scratch+'mit/rechunked/'\n",
    "\n",
    "for v in V:\n",
    "\n",
    "    file_in = scratch+'/mit/standard/%s.zarr'%(v)\n",
    "    ds0 = xr.open_zarr(file_in)\n",
    "    \n",
    "    #for face in range(ds0['face'].size):\n",
    "    for face in [1]:\n",
    "        \n",
    "        ds = ds0.isel(face=face)\n",
    "        #\n",
    "        ds = ds.isel(time=slice(len(ds.time)//Nt *Nt))\n",
    "        #\n",
    "        ds = ds.chunk({'time': Nt, 'i': Nc, 'j': Nc})\n",
    "        #\n",
    "        # tmp, xarray zarr backend bug: \n",
    "        # https://github.com/pydata/xarray/issues/2278\n",
    "        del ds['face'].encoding['chunks']\n",
    "        del ds[v].encoding['chunks']\n",
    "        \n",
    "        file_out = out_dir+'%s_f%02d.zarr'%(v,face)\n",
    "        try:\n",
    "            #%time ds.to_zarr(file_out, mode='w')\n",
    "            # specify compression:\n",
    "            %time ds.to_zarr(file_out, mode='w', \\\n",
    "                             encoding={key: {'compressor': compressor} for key in ds.variables})\n",
    "            # without compression: 601G for face 1\n",
    "        except:\n",
    "            print('Failure')\n",
    "        dsize = getsize(file_out)\n",
    "        print(' %s face=%d  data is %.1fGB ' %(v, face, dsize/1e9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = cluster.start_workers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future pending cb=[_make_coroutine_wrapper.<locals>.wrapper.<locals>.<lambda>() at /home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/gen.py:336]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/tornado/iostream.py\", line 684, in _handle_events\n",
      "    \"shouldn't happen: _handle_events without self._state\"\n",
      "AssertionError: shouldn't happen: _handle_events without self._state\n"
     ]
    }
   ],
   "source": [
    "# kill scheduler, workers\n",
    "cluster.scheduler.close()\n",
    "#cluster.stop_workers(cluster.jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
