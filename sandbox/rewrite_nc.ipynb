{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/cmocean/tools.py:76: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.\n",
      "  if not mpl.cbook.is_string_like(rgbin[0]):\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "#from dask_jobqueue import PBSCluster\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmethod = 0\n",
    "#\n",
    "if dmethod == 0:\n",
    "    client = None\n",
    "if dmethod == 1:\n",
    "    from dask.distributed import Client\n",
    "    scheduler = os.getenv('DATAWORK')+'/dask/scheduler.json'\n",
    "    client = Client(scheduler_file=scheduler)\n",
    "elif dmethod == 2:\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    # folder where data is spilled when RAM is filled up\n",
    "    local_dir = os.getenv('TMPDIR')\n",
    "    #\n",
    "    cluster = PBSCluster(queue='mpi_1', local_directory=local_dir, interface='ib0', walltime='24:00:00',\n",
    "                         threads=14, processes=2, memory='50GB', resource_spec='select=1:ncpus=28:mem=100g', \n",
    "                         death_timeout=100)\n",
    "    w = cluster.start_workers(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to wait for workers to spin up\n",
    "if dmethod == 2:\n",
    "    cluster.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "if dmethod == 2:\n",
    "    from dask.distributed import Client\n",
    "    client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# automatic rewriting of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "V = ['Eta']\n",
    "\n",
    "transpose = False\n",
    "\n",
    "#out_dir = datawork+'/mit_T/'\n",
    "#out_dir = scratch+'/mit_nc_t/'\n",
    "\n",
    "if transpose:\n",
    "    Nt = 24*10 # time windows to consider\n",
    "    out_dir = datawork+'/mit_nc_t/'\n",
    "    fsize_bound = 15*1e9\n",
    "else:\n",
    "    Nt = 1\n",
    "    out_dir = datawork+'/mit_nc/'\n",
    "    fsize_bound = 60*1e6    \n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    #it = np.arange(10).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    for face in range(ds['face'].size):\n",
    "        for i, t in enumerate(it):\n",
    "            #\n",
    "            file_out = out_dir+'/%s_f%02d_t%02d.nc'%(v,face,i)\n",
    "            if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "                dv = ds[v].isel(time=slice(t,t+Nt), face=face) \n",
    "                # should store grid data independantly in a single file\n",
    "                dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "                #\n",
    "                if transpose:\n",
    "                    dv = dv.chunk({'time': dv['time'].size, 'i': 432, 'j': 432})\n",
    "                    dv = dv.transpose('i','j','time')\n",
    "                    chunksizes = [432, 432, dv['time'].size]\n",
    "                else:\n",
    "                    dv = dv.chunk({'i': 432, 'j': 432})\n",
    "                    chunksizes = [1, 432, 432]\n",
    "                #print(dv)\n",
    "                #\n",
    "                while True:\n",
    "                    try:\n",
    "                        %time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "                                           encoding={'Eta': {'chunksizes': chunksizes}})\n",
    "                    except:\n",
    "                        print('Failure')\n",
    "                    if os.path.isfile(file_out) and os.path.getsize(file_out)>fsize_bound:\n",
    "                        #\n",
    "                        print('face=%d / i=%d'%(face,i))\n",
    "                        break\n",
    "            else:\n",
    "                print('face=%d / i=%d - allready processed'%(face,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# standard data layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ['Eta', 'SST', 'SSS', 'SSU', 'SSV']\n",
    "V = ['Eta']\n",
    "\n",
    "transpose = False # True untested\n",
    "\n",
    "#out_dir = datawork+'/mit_T/'\n",
    "#out_dir = scratch+'/mit_nc_t/'\n",
    "\n",
    "if transpose:\n",
    "    Nt = 24*10 # time windows to consider\n",
    "    out_dir = datawork+'/mit_nc_t/'\n",
    "    fsize_bound = 1e12\n",
    "else:\n",
    "    Nt = 1\n",
    "    out_dir = datawork+'/mit_nc/'\n",
    "    fsize_bound = 13*60*1e6\n",
    "\n",
    "for v in V:\n",
    "    #\n",
    "    data_dir = root_data_dir+v+'/'\n",
    "    iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "    #\n",
    "    it = np.arange(time.size/Nt-1).astype(int)*Nt\n",
    "    #it = np.arange(10).astype(int)*Nt # tmp\n",
    "    assert it[-1]+Nt<time.size\n",
    "    #\n",
    "    p = 'C'\n",
    "    if v is 'SSU':\n",
    "        p = 'W'\n",
    "    elif v is 'SSV':\n",
    "        p = 'S'\n",
    "    #\n",
    "    ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "    #ds = ds.chunk({'face': 1})\n",
    "    #\n",
    "    for i, t in enumerate(it):\n",
    "        #\n",
    "        file_out = out_dir+'/%s_t%04d.nc'%(v,i)\n",
    "        if not os.path.isfile(file_out) or os.path.getsize(file_out) < fsize_bound:            \n",
    "            dv = ds[v].isel(time=slice(t,t+Nt)) \n",
    "            # should store grid data independantly in a single file\n",
    "            dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "            #\n",
    "            if transpose:\n",
    "                dv = dv.chunk({'time': dv['time'].size, 'i': 432, 'j': 432})\n",
    "                dv = dv.transpose('face','i','j','time')\n",
    "                #chunksizes = [1, 432, 432, dv['time'].size]\n",
    "            else:\n",
    "                #dv = dv.chunk({'i': 4320, 'j': 4320})\n",
    "                #chunksizes = [1, 1, 432, 432]\n",
    "                pass\n",
    "            #print(dv)\n",
    "            #\n",
    "            while True:\n",
    "                try:\n",
    "                    print(dv)\n",
    "                    %time dv.to_netcdf(file_out, mode='w')                    \n",
    "                    #%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'])                    \n",
    "                    #%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "                    #                   encoding={'Eta': {'chunksizes': chunksizes}})\n",
    "                except:\n",
    "                    print('Failure')\n",
    "                #if os.path.isfile(file_out):\n",
    "                if os.path.isfile(file_out) and os.path.getsize(file_out) > fsize_bound:\n",
    "                    #\n",
    "                    print('i=%d, iter=%d'%(i, iters[i].values))\n",
    "                    break\n",
    "        else:\n",
    "            print('i=%d, iter=%d - allready processed'%(i, iters[i].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# preliminary attempts to transpose and store data in netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = 24*10 # time windows to consider\n",
    "v = 'Eta'\n",
    "face = 1\n",
    "out_dir = datawork+'/mit_tmp/'\n",
    "\n",
    "\n",
    "data_dir = root_data_dir+v+'/'\n",
    "iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "p = 'C'\n",
    "if v is 'SSU':\n",
    "    p = 'W'\n",
    "elif v is 'SSV':\n",
    "    p = 'S'\n",
    "ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "ds = ds.chunk({'face': 1})\n",
    "\n",
    "dv = ds[v].isel(time=slice(0,Nt), face=face)\n",
    "\n",
    "# xarray stores datasets preferentially\n",
    "dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "\n",
    "dv0 = dv\n",
    "print(dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Default chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = out_dir+'/%s_f%02d_0.nc'%(v,face)\n",
    "%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_eta = nc4.Dataset(file_out)['Eta']\n",
    "print(nc_eta)\n",
    "print(nc_eta.chunking())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### transposed dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "dv = dv0.transpose('i','j','time')\n",
    "print(dv)\n",
    "file_out = out_dir+'/%s_f%02d_1.nc'%(v,face)\n",
    "%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_eta = nc4.Dataset(file_out)['Eta']\n",
    "print(nc_eta)\n",
    "print(nc_eta.chunking())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### transpose and rechunk\n",
    "\n",
    "the xarray rechunking does not affect the netcdf chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = dv0.chunk({'time': dv['time'].size})\n",
    "dv = dv.transpose('i','j','time')\n",
    "#dv = dv0.chunk({'time': dv['time'].size, 'i': 100, 'j': 100})\n",
    "print(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = out_dir+'/%s_f%02d_2.nc'%(v,face)\n",
    "%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'])\n",
    "#%time dv.to_netcdf(file_out, mode='w') # leads to contiguous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_eta = nc4.Dataset(file_out)['Eta']\n",
    "print(nc_eta)\n",
    "print(nc_eta.chunking())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### netcdf chunks passed with encoding option\n",
    "\n",
    "takes very long time, not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = out_dir+'/%s_f%02d_3.nc'%(v,face)\n",
    "dv = dv0\n",
    "print(dv)\n",
    "print(dv['time'].size)\n",
    "#dv.to_netcdf(file_out, mode='w', encoding={'Eta': {'chunksizes': {'time': dv['time'].size, 'i': 432, 'j': 432}}})\n",
    "%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "             encoding={'Eta': {'chunksizes': [432, 432, dv['time'].size]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_eta = nc4.Dataset(file_out)['Eta']\n",
    "print(nc_eta)\n",
    "print(nc_eta.chunking())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### same but with xarray rechunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dv = dv0.chunk({'time': dv['time'].size}) # 3min 46s\n",
    "dv = dv0.chunk({'time': dv['time'].size, 'i': 432, 'j': 432}) # 50.9 s\n",
    "dv = dv.transpose('i','j','time')\n",
    "print(dv)\n",
    "\n",
    "file_out = out_dir+'/%s_f%02d_4.nc'%(v,face)\n",
    "%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'], \\\n",
    "             encoding={'Eta': {'chunksizes': [432, 432, dv['time'].size]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:721: UserWarning: Couldn't find available_diagnostics.log in . Using default version.\n",
      "  \"in %s. Using default version.\" % data_dir)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/utils.py:314: UserWarning: Not sure what to do with rlev = L\n",
      "  warnings.warn(\"Not sure what to do with rlev = \" + rlev)\n",
      "/home1/datahome/aponte/.miniconda3/envs/equinox/lib/python3.6/site-packages/xmitgcm/mds_store.py:235: FutureWarning: iteration over an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Iterate over the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n",
      "  for vname in ds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " data size: 1.0 GB\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, i_g: 4320, j: 4320, j_g: 4320, k: 90, k_l: 90, k_p1: 91, k_u: 90)\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "    Z        (k) >f4 -0.5 -1.57 -2.79 -4.185 -5.78 -7.595 -9.66 -12.01 ...\n",
      "    Zp1      (k_p1) >f4 0.0 -1.0 -2.14 -3.44 -4.93 -6.63 -8.56 -10.76 -13.26 ...\n",
      "    Zu       (k_u) >f4 -1.0 -2.14 -3.44 -4.93 -6.63 -8.56 -10.76 -13.26 ...\n",
      "    Zl       (k_l) >f4 0.0 -1.0 -2.14 -3.44 -4.93 -6.63 -8.56 -10.76 -13.26 ...\n",
      "    drC      (k_p1) >f4 0.5 1.07 1.22 1.395 1.595 1.815 2.065 2.35 2.67 ...\n",
      "    drF      (k) >f4 1.0 1.14 1.3 1.49 1.7 1.93 2.2 2.5 2.84 3.21 3.63 4.1 ...\n",
      "    PHrefC   (k) >f4 4.905 15.4017 27.3699 41.05485 56.7018 74.50695 94.7646 ...\n",
      "    PHrefF   (k_p1) >f4 0.0 9.81 20.9934 33.7464 48.3633 65.0403 83.9736 ...\n",
      "    time     float64 3.384e+05\n",
      "Data variables:\n",
      "    Eta      (face, j, i) >f4 dask.array<shape=(13, 4320, 4320), chunksize=(13, 4320, 4320)>\n",
      "Attributes:\n",
      "    Conventions:  CF-1.6\n",
      "    title:        netCDF wrapper of MITgcm MDS binary data\n",
      "    source:       MITgcm\n",
      "    history:      Created by calling `open_mdsdataset(llc_method='smallchunks...\n"
     ]
    }
   ],
   "source": [
    "Nt = 24*10 # time windows to consider\n",
    "v = 'Eta'\n",
    "out_dir = datawork+'/mit_tmp/'\n",
    "\n",
    "\n",
    "data_dir = root_data_dir+v+'/'\n",
    "iters, time = get_iters_time(v, data_dir, delta_t=25.)\n",
    "p = 'C'\n",
    "if v is 'SSU':\n",
    "    p = 'W'\n",
    "elif v is 'SSV':\n",
    "    p = 'S'\n",
    "ds = get_compressed_data(v, data_dir, grid_dir, iters=iters, time=time, client=client, point=p)\n",
    "#ds = ds.chunk({'face': 1})\n",
    "\n",
    "it=22\n",
    "dv = ds.isel(time=it)\n",
    "#dv = ds[v].isel(time=it)\n",
    "\n",
    "# xarray stores datasets preferentially\n",
    "#dv = dv.drop(['XC','YC','Depth','rA']).to_dataset()\n",
    "dv = dv.drop(['XC','YC','XG','YG','Depth','rA'])\n",
    "dv = dv.drop(['dxG','dyG','dxC','dyC','rAw','rAs','rAz'])\n",
    "dv = dv.drop(['hFacC','hFacW','hFacS'])\n",
    "\n",
    "print('\\n data size: %.1f GB' %(dv.nbytes / 1e9))\n",
    "\n",
    "dv0 = dv\n",
    "print(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/datawork/aponte/mit_tmp/Eta_t0022.nc\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         return to_netcdf(self, path, mode, format=format, group=group,\n\u001b[1;32m   1136\u001b[0m                          \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                          unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     def to_zarr(self, store=None, mode='w-', synchronizer=None, group=None,\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, writer, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         dataset.dump_to_store(store, sync=sync, encoding=encoding,\n\u001b[0;32m--> 657\u001b[0;31m                               unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mdump_to_store\u001b[0;34m(self, store, encoder, sync, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                     unlimited_dims=unlimited_dims)\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     def to_netcdf(self, path=None, mode='w', format=None, group=None,\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetCDF4DataStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;31m# datastore will be reopened during write\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mstore\u001b[0;34m(sources, targets, lock, regions, compute, return_stored, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     postcomputes = [a.__dask_postcompute__() if is_dask_collection(a)\n\u001b[1;32m    403\u001b[0m                     else (None, a) for a in args]\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0mresults_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     return tuple(a if f is None else f(next(results_iter), *a)\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[1;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                         \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                         \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/compatibility.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0margs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mstore_chunk\u001b[0;34m(x, out, index, lock, return_stored)\u001b[0m\n\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstore_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_stored\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_store_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_stored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mload_store_chunk\u001b[0;34m(x, out, index, lock, return_stored, load_stored)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_stored\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mload_stored\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "dv = dv0\n",
    "file_out = out_dir+'%s_t%04d.nc'%(v, it)\n",
    "print(file_out)\n",
    "#%time dv.to_netcdf(file_out, mode='w', unlimited_dims=['time'])\n",
    "%time dv.to_netcdf(file_out, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (face: 13, j: 4320, i: 4320)>\n",
      "array([[[-0.684281,  1.441564, ..., -0.255179, -0.551868],\n",
      "        [-0.597804,  0.273744, ...,  1.739036, -1.721006],\n",
      "        ...,\n",
      "        [-2.557045, -1.166614, ..., -0.685375, -0.659004],\n",
      "        [-0.303543,  1.063811, ..., -0.237492,  1.983176]],\n",
      "\n",
      "       [[ 2.046576,  0.979833, ..., -0.427329,  1.24397 ],\n",
      "        [-0.106713,  1.73359 , ...,  1.126007, -2.410902],\n",
      "        ...,\n",
      "        [-0.205126,  2.423796, ..., -0.989067,  1.288032],\n",
      "        [ 0.008743, -0.390828, ...,  1.568263,  0.568703]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.041188,  1.3828  , ...,  0.953397, -1.36305 ],\n",
      "        [ 1.03552 ,  0.590506, ..., -0.862716, -0.851022],\n",
      "        ...,\n",
      "        [ 0.931278, -0.295722, ...,  0.889678,  0.455275],\n",
      "        [ 0.240305, -1.784133, ..., -1.995973, -0.594844]],\n",
      "\n",
      "       [[-0.313869, -0.313098, ...,  1.505533,  1.274073],\n",
      "        [-0.601452,  1.657428, ..., -2.073899,  1.949373],\n",
      "        ...,\n",
      "        [ 0.632802,  0.351928, ..., -0.34411 , -0.70389 ],\n",
      "        [-0.353308,  0.204671, ...,  0.474517, -0.761668]]])\n",
      "Coordinates:\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n"
     ]
    }
   ],
   "source": [
    "i = np.arange(4320)\n",
    "j = np.arange(4320)\n",
    "face = np.arange(13)\n",
    "v = xr.DataArray(np.random.randn(face.size, j.size, i.size), \\\n",
    "                  coords={'i': i, 'j': j, 'face': face}, dims=['face','j','i'])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, writer, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m    656\u001b[0m         dataset.dump_to_store(store, sync=sync, encoding=encoding,\n\u001b[0;32m--> 657\u001b[0;31m                               unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mdump_to_store\u001b[0;34m(self, store, encoder, sync, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         store.store(variables, attrs, check_encoding,\n\u001b[0;32m-> 1074\u001b[0;31m                     unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m   1075\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, variables, attributes, check_encoding_set, unlimited_dims)\u001b[0m\n\u001b[1;32m    362\u001b[0m         self.set_variables(variables, check_encoding_set,\n\u001b[0;32m--> 363\u001b[0;31m                            unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mset_variables\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetCDF4DataStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36mset_variables\u001b[0;34m(self, variables, check_encoding_set, unlimited_dims)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         return to_netcdf(self, path, mode, format=format, group=group,\n\u001b[1;32m   1136\u001b[0m                          \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                          unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     def to_zarr(self, store=None, mode='w-', synchronizer=None, group=None,\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, writer, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msync\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/equinox/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isopen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset._close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "file_out = out_dir+'rand.nc'\n",
    "%time dv.to_netcdf(file_out, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "aponte/mit_tmp% ncdump -sh Eta_f01_4.nc\n",
    "\n",
    "netcdf Eta_f01_4 {\n",
    "dimensions:\n",
    "\ttime = UNLIMITED ; // (24 currently)\n",
    "\ti = 4320 ;\n",
    "\tj = 4320 ;\n",
    "variables:\n",
    "\tint64 i(i) ;\n",
    "\t\ti:standard_name = \"x_grid_index\" ;\n",
    "\t\ti:axis = \"X\" ;\n",
    "\t\ti:long_name = \"x-dimension of the t grid\" ;\n",
    "\t\ti:swap_dim = \"XC\" ;\n",
    "\t\ti:_Storage = \"contiguous\" ;\n",
    "\t\ti:_Endianness = \"little\" ;\n",
    "\tint64 j(j) ;\n",
    "\t\tj:standard_name = \"y_grid_index\" ;\n",
    "\t\tj:axis = \"Y\" ;\n",
    "\t\tj:long_name = \"y-dimension of the t grid\" ;\n",
    "\t\tj:swap_dim = \"YC\" ;\n",
    "\t\tj:_Storage = \"contiguous\" ;\n",
    "\t\tj:_Endianness = \"little\" ;\n",
    "\tint64 face ;\n",
    "\t\tface:standard_name = \"face_index\" ;\n",
    "\t\tface:_Endianness = \"little\" ;\n",
    "\tdouble time(time) ;\n",
    "\t\ttime:_FillValue = NaN ;\n",
    "\t\ttime:_Storage = \"chunked\" ;\n",
    "\t\ttime:_ChunkSizes = 512 ;\n",
    "\tfloat Eta(i, j, time) ;\n",
    "\t\tEta:_FillValue = NaNf ;\n",
    "\t\tEta:coordinates = \"face\" ;\n",
    "\t\tEta:_Storage = \"chunked\" ;\n",
    "\t\tEta:_ChunkSizes = 432, 432, 24 ;\n",
    "\n",
    "// global attributes:\n",
    "\t\t:_NCProperties = \"version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.1\" ;\n",
    "\t\t:_Format = \"netCDF-4\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
