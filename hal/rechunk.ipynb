{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rewrite data with larger chunks along time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mitequinox.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(cores=1)\n",
    "#print(cluster.job_script())\n",
    "w = cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dask handles and check dask server status\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.135.39.91:42604\n",
       "  <li><b>Dashboard: </b><a href='http://10.135.39.91:8787/status' target='_blank'>http://10.135.39.91:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>30</li>\n",
       "  <li><b>Cores: </b>30</li>\n",
       "  <li><b>Memory: </b>1.20 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.135.39.91:42604' processes=30 cores=30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# try to load standard lay out, rechunk and store right away\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-15 00:00:00  to  2012-11-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# same but over all variables and faces\n",
    "#V = ['SSU', 'SSV', 'Eta']\n",
    "V = ['SST']\n",
    "\n",
    "# parameters for rechunking: time and space\n",
    "#Nt0, Nc = 24*10, (96, 48) # choice 0, leads to files <4MB\n",
    "Nt0, Nc = 24*20, (288, 96) # choice 1, to be tested\n",
    "#\n",
    "# 96 x 45 = 4320\n",
    "# other choices: 432, 27 (long scheduling), 288, 864\n",
    "\n",
    "df = load_common_timeline(V)\n",
    "\n",
    "# zarr compression\n",
    "# http://xarray.pydata.org/en/stable/io.html\n",
    "# http://zarr.readthedocs.io/en/stable/tutorial.html#compressors\n",
    "#compressor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one face at a time, all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**netcdf**: Goes through with 20 workers, 20 cores, 800GB, `chunks={'face':1, 'j':480}` and all  files.\n",
    "Memory saturates at 415GB, i.e. there is probably NO spilling to tmp disk. Wall time= 25min/face\n",
    "\n",
    "**zarr**: you need to explicetly delete the chunks encoding but otherwise works great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start SSU\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i_g: 4320, j: 4320, time: 8785)\n",
      "Coordinates:\n",
      "    dtime    (time) datetime64[ns] dask.array<shape=(8785,), chunksize=(8785,)>\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "    iters    (time) int64 dask.array<shape=(8785,), chunksize=(1,)>\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.732e+07 3.732e+07\n",
      "Data variables:\n",
      "    SSU      (time, face, j, i_g) float32 dask.array<shape=(8785, 13, 4320, 4320), chunksize=(1, 1, 4320, 4320)>\n",
      "CPU times: user 4min 2s, sys: 10.7 s, total: 4min 13s\n",
      "Wall time: 4min 16s\n",
      " SSU face=0  data is 189.2GB \n",
      " SSU face=1  data is 414.0GB \n",
      " SSU face=2  data is 265.8GB \n",
      "CPU times: user 3min 58s, sys: 11.2 s, total: 4min 9s\n",
      "Wall time: 4min 15s\n",
      " SSU face=3  data is 128.8GB \n",
      "CPU times: user 4min 15s, sys: 12.1 s, total: 4min 27s\n",
      "Wall time: 4min 35s\n",
      " SSU face=4  data is 468.3GB \n",
      "CPU times: user 3min 57s, sys: 9.79 s, total: 4min 7s\n",
      "Wall time: 4min 11s\n",
      " SSU face=5  data is 87.2GB \n",
      "CPU times: user 4min 14s, sys: 11.3 s, total: 4min 25s\n",
      "Wall time: 4min 34s\n",
      " SSU face=6  data is 377.9GB \n",
      "CPU times: user 4min 14s, sys: 12.1 s, total: 4min 26s\n",
      "Wall time: 4min 37s\n",
      " SSU face=7  data is 405.8GB \n",
      "CPU times: user 4min 23s, sys: 12.4 s, total: 4min 35s\n",
      "Wall time: 4min 49s\n",
      " SSU face=8  data is 513.8GB \n",
      "CPU times: user 4min 1s, sys: 11.2 s, total: 4min 12s\n",
      "Wall time: 4min 18s\n",
      " SSU face=9  data is 250.5GB \n",
      " SSU face=10  data is 255.9GB \n",
      " SSU face=11  data is 415.4GB \n",
      "CPU times: user 4min, sys: 11 s, total: 4min 11s\n",
      "Wall time: 4min 18s\n",
      " SSU face=12  data is 232.9GB \n",
      "--- Start SSV\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, j_g: 4320, time: 8785)\n",
      "Coordinates:\n",
      "    dtime    (time) datetime64[ns] dask.array<shape=(8785,), chunksize=(8785,)>\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "    iters    (time) int64 dask.array<shape=(8785,), chunksize=(1,)>\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.732e+07 3.732e+07\n",
      "Data variables:\n",
      "    SSV      (time, face, j_g, i) float32 dask.array<shape=(8785, 13, 4320, 4320), chunksize=(1, 1, 4320, 4320)>\n",
      "CPU times: user 4min 4s, sys: 10.2 s, total: 4min 14s\n",
      "Wall time: 4min 21s\n",
      " SSV face=0  data is 191.5GB \n",
      " SSV face=1  data is 419.4GB \n",
      " SSV face=2  data is 267.9GB \n",
      "CPU times: user 3min 59s, sys: 11 s, total: 4min 10s\n",
      "Wall time: 4min 16s\n",
      " SSV face=3  data is 131.1GB \n",
      "CPU times: user 4min 19s, sys: 12.4 s, total: 4min 31s\n",
      "Wall time: 4min 41s\n",
      " SSV face=4  data is 474.1GB \n",
      "CPU times: user 4min 1s, sys: 10.3 s, total: 4min 11s\n",
      "Wall time: 4min 16s\n",
      " SSV face=5  data is 87.7GB \n",
      "CPU times: user 4min 12s, sys: 11.7 s, total: 4min 24s\n",
      "Wall time: 4min 31s\n",
      " SSV face=6  data is 379.7GB \n",
      "CPU times: user 4min 15s, sys: 12.1 s, total: 4min 27s\n",
      "Wall time: 4min 34s\n",
      " SSV face=7  data is 401.9GB \n",
      "CPU times: user 4min 24s, sys: 12.4 s, total: 4min 36s\n",
      "Wall time: 4min 51s\n",
      " SSV face=8  data is 503.5GB \n",
      "CPU times: user 4min 8s, sys: 11 s, total: 4min 19s\n",
      "Wall time: 4min 26s\n",
      " SSV face=9  data is 249.1GB \n",
      " SSV face=10  data is 255.1GB \n",
      " SSV face=11  data is 406.9GB \n",
      "CPU times: user 4min 3s, sys: 11 s, total: 4min 14s\n",
      "Wall time: 4min 20s\n",
      " SSV face=12  data is 233.2GB \n",
      "--- Start Eta\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, j: 4320, time: 8785)\n",
      "Coordinates:\n",
      "    dtime    (time) datetime64[ns] dask.array<shape=(8785,), chunksize=(8785,)>\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "    iters    (time) int64 dask.array<shape=(8785,), chunksize=(1,)>\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * time     (time) float64 5.702e+06 5.706e+06 5.71e+06 ... 3.732e+07 3.732e+07\n",
      "Data variables:\n",
      "    Eta      (time, face, j, i) float32 dask.array<shape=(8785, 13, 4320, 4320), chunksize=(1, 1, 4320, 4320)>\n",
      "CPU times: user 4min 3s, sys: 9.98 s, total: 4min 12s\n",
      "Wall time: 4min 18s\n",
      " Eta face=0  data is 161.8GB \n",
      " Eta face=1  data is 349.3GB \n",
      " Eta face=2  data is 223.5GB \n",
      "CPU times: user 4min, sys: 10.4 s, total: 4min 10s\n",
      "Wall time: 4min 16s\n",
      " Eta face=3  data is 108.7GB \n",
      "CPU times: user 4min 18s, sys: 12.3 s, total: 4min 30s\n",
      "Wall time: 4min 40s\n",
      " Eta face=4  data is 391.6GB \n",
      "CPU times: user 3min 56s, sys: 10.2 s, total: 4min 6s\n",
      "Wall time: 4min 10s\n",
      " Eta face=5  data is 73.2GB \n",
      "CPU times: user 4min 8s, sys: 10.6 s, total: 4min 19s\n",
      "Wall time: 4min 26s\n",
      " Eta face=6  data is 329.8GB \n",
      "CPU times: user 4min 12s, sys: 11.7 s, total: 4min 23s\n",
      "Wall time: 4min 31s\n",
      " Eta face=7  data is 335.4GB \n",
      "CPU times: user 4min 19s, sys: 12.6 s, total: 4min 32s\n",
      "Wall time: 4min 42s\n",
      " Eta face=8  data is 419.2GB \n",
      "CPU times: user 4min 5s, sys: 11.2 s, total: 4min 16s\n",
      "Wall time: 4min 23s\n",
      " Eta face=9  data is 213.1GB \n",
      " Eta face=10  data is 219.9GB \n",
      " Eta face=11  data is 346.5GB \n",
      "CPU times: user 4min 4s, sys: 10.9 s, total: 4min 15s\n",
      "Wall time: 4min 23s\n",
      " Eta face=12  data is 196.2GB \n"
     ]
    }
   ],
   "source": [
    "out_dir = work_data_dir+'rechunked/'\n",
    "overwrite=False\n",
    "\n",
    "for v in V:\n",
    "\n",
    "    print('--- Start '+v)\n",
    "    \n",
    "    #files = load_iters_date_files(v).file[:500].tolist()\n",
    "    #ds0 = load_datanc(v, files=files, parallel=True)\n",
    "    #if v is 'SSV':\n",
    "    #    ds0 = load_datanc(v,  parallel=True, chunks={'face':1, 'j_g':480})\n",
    "    #else:\n",
    "    #    ds0 = load_datanc(v, parallel=True, chunks={'face':1, 'j':480})            \n",
    "    #print(ds0)\n",
    "    ds0 = load_data(v) #.isel(time=slice(1000))   \n",
    "    \n",
    "    # select common time line\n",
    "    t0 = ds0['time'].where(ds0.iters==df['iter'][0],drop=True).values[0]\n",
    "    t1 = ds0['time'].where(ds0.iters==df['iter'][-1],drop=True).values[0]\n",
    "    ds0 = ds0.sel(time=slice(t0,t1))\n",
    "  \n",
    "    Nt = len(ds0.time) if Nt0 == 0 else Nt0\n",
    "    print(ds0)\n",
    "    \n",
    "    #for face in [1]:\n",
    "    #for face in [1,2,10,11]:\n",
    "    for face in range(ds0['face'].size):\n",
    "    \n",
    "        \n",
    "        ds = ds0.isel(face=face)\n",
    "        #\n",
    "        ds = ds.isel(time=slice(len(ds.time)//Nt *Nt))\n",
    "        #\n",
    "        chunks = {'time': Nt, 'i': Nc[0], 'j': Nc[1]}\n",
    "        if v is 'SSU':\n",
    "            chunks = {'time': Nt, 'i_g': Nc[0], 'j': Nc[1]}\n",
    "        elif v is 'SSV':\n",
    "            chunks = {'time': Nt, 'i': Nc[0], 'j_g': Nc[1]}\n",
    "        ds = ds.chunk(chunks)\n",
    "        \n",
    "        # tmp, xarray zarr backend bug: \n",
    "        # https://github.com/pydata/xarray/issues/2278\n",
    "        del ds['iters'].encoding['chunks']\n",
    "        del ds[v].encoding['chunks']\n",
    "        \n",
    "        file_out = out_dir+'%s_f%02d.zarr'%(v,face)\n",
    "        #print(ds)\n",
    "        if not os.path.isdir(file_out) or overwrite:\n",
    "            %time ds.to_zarr(file_out, mode='w')\n",
    "            \n",
    "        dsize = getsize(file_out)\n",
    "        print(' %s face=%d  data is %.1fGB ' %(v, face, dsize/1e9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rechunked all faces \n",
    "\n",
    "**netcdf**: Goes through with 20 workers, 20 cores, 800GB, `chunks={'face':1, 'j':480}` and **1000 files** (i.e not the full dataset!).\n",
    "Memory saturates at 515GB, approx 70% of 800GB (560GB truly), i.e. there is spilling to tmp disk. Wall time= 40min\n",
    "\n",
    "**zarr**: scheduler takes a while to start file writting with full dataset, I had to stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = work_data_dir+'rechunked/'\n",
    "\n",
    "for v in V:\n",
    "\n",
    "    #files = load_iters_date_files(v).file[:1000].tolist()\n",
    "    #ds0 = load_datanc(v, files=files, parallel=True)\n",
    "    #ds0 = load_datanc(v, parallel=True)\n",
    "    #ds0 = load_datanc(v, files=files, parallel=True, \n",
    "    #                  chunks={'face':1, 'j':480})\n",
    "    ds0 = load_data(v)\n",
    "    \n",
    "    # select common time line\n",
    "    ds0 = ds0.sel(time=slice(df.index[0],df.index[-1])    \n",
    "    \n",
    "    Nt = len(ds0.time) if Nt0 == 0 else Nt0\n",
    "    \n",
    "    #\n",
    "    ds = ds0.isel(time=slice(len(ds0.time)//Nt *Nt))\n",
    "    #\n",
    "    chunks = {'time': Nt, 'i': Nc[0], 'j': Nc[1]}\n",
    "    if v is 'SSU':\n",
    "        chunks = {'time': Nt, 'i_g': Nc[0], 'j': Nc[1]}\n",
    "    elif v is 'SSV':\n",
    "        chunks = {'time': Nt, 'i': Nc[0], 'j_g': Nc[1]}\n",
    "    ds = ds.chunk(chunks)\n",
    "    print(ds)\n",
    "\n",
    "    # tmp, xarray zarr backend bug: \n",
    "    # https://github.com/pydata/xarray/issues/2278\n",
    "    del ds['iters'].encoding['chunks']\n",
    "    del ds[v].encoding['chunks']    \n",
    "    \n",
    "    file_out = out_dir+'%s_rechunked.zarr'%(v)\n",
    "    %time ds.to_zarr(file_out, mode='w')\n",
    "\n",
    "    dsize = getsize(file_out)\n",
    "    print(' %s  data is %.1fGB ' %(v, dsize/1e9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common time line and chunks across variables, standard layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-15 00:00:00  to  2012-11-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#V = ['SSU', 'SSV', 'Eta']\n",
    "V = ['SSS']\n",
    "Nt0, Nc = 1, (None, None) # leads to files ??\n",
    "\n",
    "df = load_common_timeline(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 10s, sys: 1min 22s, total: 22min 33s\n",
      "Wall time: 41min 23s\n",
      " SSS  data is 2624.2GB \n"
     ]
    }
   ],
   "source": [
    "out_dir = work_data_dir+'rechunked/'\n",
    "\n",
    "for v in V:\n",
    "\n",
    "    #ds0 = load_datanc(v, files=files, parallel=True)\n",
    "    #files = df['file_'+v][:500].tolist()\n",
    "    files = df['file_'+v][:].tolist()\n",
    "    ds0 = load_data(v, ftype='nc', files=files, parallel=True, chunks={'face':1})\n",
    "    \n",
    "    Nt = len(ds0.time) if Nt0 == 0 else Nt0\n",
    "        \n",
    "    ds = ds0.isel(time=slice(len(ds0.time)//Nt *Nt))\n",
    "    #\n",
    "    chunks = {'time': Nt, 'i': Nc[0], 'j': Nc[1]}\n",
    "    if v is 'SSU':\n",
    "        chunks = {'time': Nt, 'i_g': Nc[0], 'j': Nc[1]}\n",
    "    elif v is 'SSV':\n",
    "        chunks = {'time': Nt, 'i': Nc[0], 'j_g': Nc[1]}\n",
    "    ds = ds.chunk(chunks)\n",
    "    #\n",
    "    file_out = out_dir+'%s_std.zarr'%(v)\n",
    "    #print(ds)\n",
    "    if not os.path.isdir(file_out):\n",
    "        try:\n",
    "            %time ds.to_zarr(file_out, mode='w')\n",
    "            pass\n",
    "        except:\n",
    "            print('Failure')\n",
    "    dsize = getsize(file_out)\n",
    "    print(' %s  data is %.1fGB ' %(v, dsize/1e9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# grid under zarr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (face: 13, i: 4320, i_g: 4320, j: 4320, j_g: 4320, k: 90, k_l: 90, k_p1: 91, k_u: 90)\n",
      "Coordinates:\n",
      "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
      "    Z        (k) float32 ...\n",
      "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * j        (j) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "  * face     (face) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
      "    dyG      (face, j, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "  * i        (i) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "    XC       (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 ... 4313 4314 4315 4316 4317 4318 4319\n",
      "    YG       (face, j_g, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
      "    Zu       (k_u) float32 ...\n",
      "    rAz      (face, j_g, i_g) float32 ...\n",
      "    SN       (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    hFacW    (face, j, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    YC       (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
      "    Zl       (k_l) float32 ...\n",
      "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 81 82 83 84 85 86 87 88 89 90\n",
      "    PHrefF   (k_p1) float32 ...\n",
      "    drF      (k) float32 ...\n",
      "    dxC      (face, j, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    PHrefC   (k) float32 ...\n",
      "    drC      (k_p1) float32 ...\n",
      "    hFacC    (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    rAs      (face, j_g, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    dxG      (face, j_g, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    rAw      (face, j, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    CS       (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    rA       (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    hFacS    (face, j_g, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    dyC      (face, j_g, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    Zp1      (k_p1) float32 ...\n",
      "    XG       (face, j_g, i_g) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "    Depth    (face, j, i) float32 dask.array<shape=(13, 4320, 4320), chunksize=(1, 4320, 4320)>\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x2aec45d87d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = load_grdnc()\n",
    "# should rechunk maybe\n",
    "print(grd)\n",
    "grd.to_zarr(root_data_dir+'grid.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = cluster.scale_up(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equinox",
   "language": "python",
   "name": "equinox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
